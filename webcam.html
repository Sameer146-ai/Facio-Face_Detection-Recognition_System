<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Real-Time Emotion Tracker</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
      :root {
        --bg-dark: #0f0f0f;
        --text-dark: #f1f1f1;
        --accent-dark: #00ffd0;

        --bg-light: #f9f9f9;
        --text-light: #111;
        --accent-light: #0077cc;

        --glass-bg-dark: rgba(255, 255, 255, 0.05);
        --glass-bg-light: rgba(0, 0, 0, 0.05);
      }

      * {
        box-sizing: border-box;
      }

      body {
        margin: 0;
        padding: 0;
        font-family: "Segoe UI", sans-serif;
        background: var(--bg-dark);
        color: var(--text-dark);
        transition: background 0.4s, color 0.4s;
        overflow: hidden;
        height: 100vh;
      }

      body.light-mode {
        background: var(--bg-light);
        color: var(--text-light);
      }

      h1 {
        text-align: center;
        margin: 20px;
        font-weight: 600;
      }

      #video-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        align-items: flex-start;
        gap: 20px;
        padding: 20px;
      }

      video {
        border-radius: 16px;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        max-width: 100%;
      }

      canvas#overlay {
        position: absolute;
        top: 0;
        left: 0;
      }

      #mood {
        font-size: 2rem;
        font-weight: bold;
        text-align: center;
        margin-top: 10px;
        color: var(--accent-dark);
        text-shadow: 1px 1px 3px #000;
      }

      body.light-mode #mood {
        color: var(--accent-light);
        text-shadow: none;
      }

      #leftControls,
      #smartAnalysis,
      #history,
      #chart-container {
        background: var(--glass-bg-dark);
        border-radius: 16px;
        padding: 16px;
        backdrop-filter: blur(6px);
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        width: 220px;
        font-size: 0.95rem;
        transition: background 0.3s;
      }

      body.light-mode #leftControls,
      body.light-mode #smartAnalysis,
      body.light-mode #history,
      body.light-mode #chart-container {
        background: var(--glass-bg-light);
      }

      #micBtn,
      #modeToggle {
        padding: 10px 16px;
        margin-bottom: 12px;
        width: 100%;
        border: none;
        border-radius: 10px;
        background-color: var(--accent-dark);
        color: #000;
        font-weight: 600;
        cursor: pointer;
        transition: background 0.3s, transform 0.2s;
      }

      #modeToggle {
        position: absolute;
        top: 20px;
        right: 20px;
        width: auto;
        padding: 8px 14px;
        font-size: 0.9rem;
      }

      #micBtn:hover,
      #modeToggle:hover {
        background-color: #00e6ba;
        transform: scale(1.02);
      }

      body.light-mode #micBtn,
      body.light-mode #modeToggle {
        background-color: var(--accent-light);
        color: white;
      }

      body.light-mode #micBtn:hover,
      body.light-mode #modeToggle:hover {
        background-color: #005fa3;
      }

      #transcript {
        background: rgba(0, 0, 0, 0.15);
        border-radius: 10px;
        padding: 10px;
        height: 100px;
        overflow-y: auto;
      }

      #history h3,
      #smartAnalysis h3 {
        margin-top: 0;
        margin-bottom: 10px;
        font-size: 1.1rem;
      }

      #historyList {
        list-style: none;
        padding: 0;
        margin: 0;
        max-height: 200px;
        overflow-y: auto;
      }

      #historyList li {
        padding: 6px 0;
        border-bottom: 1px solid rgba(255, 255, 255, 0.1);
      }

      #smartAnalysis p {
        margin: 6px 0;
      }

      #chart-container {
        position: absolute;
        bottom: 20px;
        left: 20px;
        width: 250px;
      }

      #chart-container canvas {
        width: 100% !important;
        height: 180px !important;
      }

      /* Chart.js Styling */
      .chartjs-render-monitor {
        background-color: transparent;
      }

      .chartjs-tooltip {
        color: #fff;
        font-size: 0.9rem;
      }

      /* Media Queries for Mobile */
      @media (max-width: 768px) {
        #video-container {
          flex-direction: column;
          align-items: center;
        }

        #video {
          width: 95%;
          max-width: 720px;
          height: auto;
        }

        #mood {
          font-size: 1.5rem;
          margin-top: 10px;
        }

        #leftControls,
        #smartAnalysis,
        #history,
        #chart-container {
          width: 100%;
          margin-bottom: 20px;
        }

        #micBtn,
        #modeToggle {
          width: 100%;
        }

        #chart-container {
          position: relative;
          margin-top: 20px;
        }
      }

      #exitBtn {
        position: fixed;
        bottom: 20px;
        right: 20px;
        padding: 10px 16px;
        border: none;
        border-radius: 10px;
        background-color: rgb(21, 212, 202);
        color: rgb(0, 0, 0);
        font-weight: bold;
        cursor: pointer;
        z-index: 999;
        box-shadow: 0 4px 8px rgba(0,0,0,0.3);
        transition: background 0.3s, transform 0.2s;
      }

      #exitBtn:hover {
        background-color: darkred;
        transform: scale(1.05);
      }

    </style>
  </head>
  <body>
    <h1>üé≠ Real-Time Emotion Tracker</h1>
    <button id="modeToggle">üåû Light Mode</button>

    <div id="video-container">
      <!-- Left Controls -->
      <div id="leftControls">
        <button id="micBtn">üé§ Start Listening</button>
        <div id="transcript">Transcript will appear here...</div>
      </div>

      <!-- Video & Overlay -->
      <div style="position: relative">
        <video id="video" width="720" height="560" autoplay muted></video>
        <canvas id="overlay"></canvas>
      </div>

      <!-- Right Analysis -->
      <div id="smartAnalysis">
        <h3>üìä Smart Analysis</h3>
        <p><strong>Avg Mood Today:</strong> <span id="avgMood">-</span></p>
        <p><strong>Most Frequent Emotion:</strong> <span id="mostFrequent">-</span></p>
        <p><strong>Face Detections:</strong> <span id="faceCount">0</span></p>
        <p><strong>Session Time:</strong> <span id="sessionTime">0s</span></p>
      </div>

      <!-- Mood History -->
      <div id="history">
        <h3>üïí Mood History</h3>
        <ul id="historyList"></ul>
      </div>
    </div>

    <!-- Mood Display -->
    <div id="mood">Detecting...</div>

    <!-- Chart Container -->
    <div id="chart-container">
      <canvas id="moodChart"></canvas>
    </div>

    <!-- Exit Button -->
   <a href="/welcome.html"><button id="exitBtn">üèÉ‚Äç‚û°Ô∏è Exit</button></a>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
      let detectionPaused = false;

      const video = document.getElementById("video");
      const canvas = document.getElementById("overlay");
      const moodDisplay = document.getElementById("mood");
      const micBtn = document.getElementById("micBtn");
      const transcriptDiv = document.getElementById("transcript");
      const modeToggle = document.getElementById("modeToggle");
      const historyList = document.getElementById("historyList");
      const avgMoodSpan = document.getElementById("avgMood");
      const mostFrequentSpan = document.getElementById("mostFrequent");
      const faceCountSpan = document.getElementById("faceCount");
      const sessionTimeSpan = document.getElementById("sessionTime");

      let recognition;
      let listening = false;
      let lastLoggedMood = "";
      let emotionCounts = {};
      let faceDetections = 0;
      let startTime = Date.now();

      const emojiMap = {
        neutral: "üòê",
        happy: "üòÑ",
        sad: "üò¢",
        angry: "üò†",
        fearful: "üò®",
        disgusted: "ü§¢",
        surprised: "üò≤",
      };

      const chartCtx = document.getElementById("moodChart").getContext("2d");
      const moodChart = new Chart(chartCtx, {
        type: "bar",
        data: {
          labels: [],
          datasets: [
            {
              label: "Emotion Frequency",
              backgroundColor: "rgba(255, 255, 255, 0.6)",
              borderColor: "#333",
              data: [],
            },
          ],
        },
        options: {
          plugins: { legend: { display: false } },
          scales: {
            y: { beginAtZero: true },
          },
        },
      });

      async function startApp() {
        await faceapi.nets.tinyFaceDetector.loadFromUri(
          "./models/tiny_face_detector"
        );
        await faceapi.nets.faceExpressionNet.loadFromUri(
          "./models/face_expression"
        );

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: {},
          });
          video.srcObject = stream;
        } catch (err) {
          console.error("Camera error:", err);
        }
      }

      function setupSpeechRecognition() {
        const SpeechRecognition =
          window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
          transcriptDiv.innerText = "Speech recognition not supported üò¢";
          return;
        }

        recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.interimResults = true;

        recognition.onresult = (event) => {
          let transcript = "";
          for (let i = event.resultIndex; i < event.results.length; i++) {
            transcript += event.results[i][0].transcript;
          }
          transcriptDiv.innerText = transcript;

          const command = transcript.toLowerCase();
          if (command.includes("detect again")) startApp();
          else if (command.includes("pause music"))
            console.log("üîá Music paused (placeholder)");
          else if (command.includes("switch to dark mode")) {
            document.body.classList.remove("light-mode");
            modeToggle.textContent = "üåû Light Mode";
          } else if (command.includes("switch to light mode")) {
            document.body.classList.add("light-mode");
            modeToggle.textContent = "üåô Dark Mode";
          } else if (command.includes("pause detection")) {
            detectionPaused = true;
            moodDisplay.innerText = "Detection paused ‚è∏Ô∏è";
          } else if (command.includes("resume detection")) {
            detectionPaused = false;
            moodDisplay.innerText = "Resuming detection...";
          }  else if (command.includes("Tell Me the session time")) {
            const seconds = Math.floor((Date.now() - startTime) / 1000);
            const minutes = Math.floor(seconds / 60);
            const remaining = seconds % 60;
            const synth = window.speechSynthesis;
            const msg = new SpeechSynthesisUtterance(
              `You have been tracked for ${minutes} minutes and ${remaining} seconds.`
            );
            synth.speak(msg);
          } else if (
            command.includes("what can I say") ||
            command.includes("list commands")
          ) {
            alert(`üó£Ô∏è Available Voice Commands:
‚Ä¢ detect again
‚Ä¢ pause detection / resume detection
‚Ä¢ switch to dark mode / light mode
‚Ä¢ start camera / stop camera
‚Ä¢ what's my mood
‚Ä¢ clear history
‚Ä¢ what can I say / list commands`);
          } else if (command.includes("start camera")) {
            const stream = video.srcObject;
            if (!stream) startApp();
          } else if (command.includes("stop camera")) {
            const stream = video.srcObject;
            if (stream) {
              const tracks = stream.getTracks();
              tracks.forEach((track) => track.stop());
              video.srcObject = null;
            }
          } else if (
            command.includes("what's my mood") ||
            command.includes("what is my mood")
          ) {
            alert(`Your current mood is: ${moodDisplay.innerText}`);
          } else if (command.includes("clear history")) {
            historyList.innerHTML = "";
            emotionCounts = {};
            moodChart.data.labels = [];
            moodChart.data.datasets[0].data = [];
            moodChart.update();
          }
        };

        recognition.onend = () => {
          if (listening) recognition.start();
        };
      }

      micBtn.addEventListener("click", () => {
        if (!recognition) setupSpeechRecognition();

        if (!listening) {
          recognition.start();
          micBtn.textContent = "üõë Stop Listening";
          listening = true;
        } else {
          recognition.stop();
          micBtn.textContent = "üé§ Start Listening";
          listening = false;
        }
      });

      modeToggle.addEventListener("click", () => {
        document.body.classList.toggle("light-mode");
        const isLight = document.body.classList.contains("light-mode");
        modeToggle.textContent = isLight ? "üåô Dark Mode" : "üåû Light Mode";
      });

      video.addEventListener("play", () => {
        const displaySize = { width: video.width, height: video.height };
        faceapi.matchDimensions(canvas, displaySize);

        setInterval(async () => {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceExpressions();
            if (detectionPaused) return;

          const resizedDetections = faceapi.resizeResults(
            detections,
            displaySize
          );
          canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resizedDetections);
          faceapi.draw.drawFaceExpressions(canvas, resizedDetections);

          if (detections.length > 0) {
            faceDetections++;
            const expressions = detections[0].expressions;
            const maxValue = Math.max(...Object.values(expressions));
            const emotion = Object.keys(expressions).find(
              (key) => expressions[key] === maxValue
            );

            moodDisplay.innerText = `Current Mood: ${emotion} ${
              emojiMap[emotion] || ""
            }`;

            // Track emotion frequency
            emotionCounts[emotion] = (emotionCounts[emotion] || 0) + 1;
            updateSmartPanel();

            if (lastLoggedMood !== emotion) {
              lastLoggedMood = emotion;
              const now = new Date();
              const time = now.toLocaleTimeString([], {
                hour: "2-digit",
                minute: "2-digit",
              });
              const item = document.createElement("li");
              item.textContent = `üïí ${time} - ${emotion} ${
                emojiMap[emotion] || ""
              }`;
              historyList.prepend(item);
              if (historyList.children.length > 20) {
                historyList.removeChild(historyList.lastChild);
              }
            }
          } else {
            moodDisplay.innerText = "No face detected üò∂";
          }

          sessionTimeSpan.textContent = `${Math.floor(
            (Date.now() - startTime) / 1000
          )}s`;
          faceCountSpan.textContent = faceDetections;
        }, 300);
      });

      function updateSmartPanel() {
        const total = Object.values(emotionCounts).reduce((a, b) => a + b, 0);
        if (total === 0) return;

        const avg = (((emotionCounts.happy || 0) / total) * 100).toFixed(1);
        avgMoodSpan.textContent = `${avg}% Happy`;

        const most = Object.entries(emotionCounts).sort(
          (a, b) => b[1] - a[1]
        )[0];
        mostFrequentSpan.textContent = `${most[0]} ${emojiMap[most[0]]}`;

        moodChart.data.labels = Object.keys(emotionCounts);
        moodChart.data.datasets[0].data = Object.values(emotionCounts);
        moodChart.update();
      }

      startApp();
    </script>
  </body>
</html>
